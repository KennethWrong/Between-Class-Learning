{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import required modules"
      ],
      "metadata": {
        "id": "Fbl7x0jbb3LF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QAY3MqhRC6fS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting drive\n",
        "## Uncomment if you want to save the models to your drive"
      ],
      "metadata": {
        "id": "ZmsTpz7lb-6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "bAMxo7qi4iB5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PATH = \"/path/to/directory\"\n",
        "# def save_model(model_name, file_path, model):\n",
        "#   model_save_name = model_name\n",
        "#   file_path += f\"{model_name}.pt\"\n",
        "#   torch.save(model.state_dict(), file_path)\n",
        "\n",
        "# def load_model(model_name, file_path, model):\n",
        "#   file_path += f\"{model_name}.pt\"\n",
        "#   model.load_state_dict(torch.load(file_path))"
      ],
      "metadata": {
        "id": "ws_Gmlg6Rq63"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting GPU runtime if available\n",
        "dev = \"cpu\"\n",
        "if torch.cuda.is_available():\n",
        "    dev = \"cuda:0\"\n",
        "\n",
        "device = torch.device(dev)\n",
        "print(device)"
      ],
      "metadata": {
        "id": "fUHtpDbUvbLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mixer class\n",
        "This serves as an interface to get the training and testing datasets as well as mixing them."
      ],
      "metadata": {
        "id": "7tvjkUymcavT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math\n",
        "\n",
        "class Mixer:\n",
        "    def __init__(self):\n",
        "        #This is the data augmentation as described in the original paper\n",
        "        self.transform = transforms.Compose([\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                                        transforms.RandomHorizontalFlip(1),\n",
        "                                        transforms.Pad(4),\n",
        "                                        transforms.RandomCrop(32),\n",
        "                                        ])\n",
        "        \n",
        "        self.no_transform = transforms.Compose([transforms.ToTensor()])\n",
        "        self.cifar_train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
        "        self.cifar_test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True)\n",
        "    \n",
        "    #Naive between-class mixing method (BC)\n",
        "    def mix_images_bc(self, img1, img2):\n",
        "        ratio = random.uniform(0.5, 1)\n",
        "        \n",
        "        #While loop to correct value if ratio is exactly 0.5, want it to be > 0.5 to get single class label\n",
        "        while ratio == 0.5:\n",
        "            ratio = random.uniform(0.5, 1)\n",
        "        mixed_image = img1 * ratio + img2 * (1 - ratio)\n",
        "\n",
        "        return mixed_image, ratio\n",
        "\n",
        "    # Advanced between-class mixing method (BC+)\n",
        "    def mix_images_bc_plus(self, img1, img2):\n",
        "        #Better mixing method\n",
        "        ratio = random.uniform(0.5, 1)\n",
        "\n",
        "        #While loop to correct value if ratio is exactly 0.5, want it to be > 0.5 to get single class label\n",
        "        while ratio == 0.5:\n",
        "            ratio = random.uniform(0.5, 1)\n",
        "        i1_mean, i2_mean = torch.mean(img1), torch.mean(img2)\n",
        "        i1_std, i2_std = torch.std(img1), torch.std(img2)\n",
        "        p = 1 / (1 + (i1_std / i2_std) * ((1 - ratio) / ratio)) \n",
        "\n",
        "        mixed_image = (p * (img1 - i1_mean) + (1 - p) * (img2 - i2_mean)) / (math.sqrt(p ** 2 + (1 - p) ** 2))\n",
        "        # mixed_image = torch.where(mixed_image > 255, 255, mixed_image)\n",
        "\n",
        "        return mixed_image, ratio\n",
        "    \n",
        "    #Returns test dataset to users. Default transformation is False as we want it to test accurac for original CIFAR-10 dataset\n",
        "    def get_test_dataset(self, transform = False):\n",
        "        testing_size = len(self.cifar_test_set.data)\n",
        "        original_test_set = torch.empty((testing_size, 3, 32, 32), dtype=float)\n",
        "        original_test_set_label = []\n",
        "        \n",
        "        for i, data in enumerate(self.cifar_test_set.data):\n",
        "            data = Image.fromarray(data)\n",
        "            if transform:\n",
        "                data = self.transform(data)\n",
        "            else:\n",
        "                data = self.no_transform(data)\n",
        "            original_test_set[i] = data\n",
        "            original_test_set_label.append(self.cifar_test_set.targets[i])\n",
        "        \n",
        "        original_test_set_label = F.one_hot(torch.tensor(original_test_set_label))\n",
        "\n",
        "        return original_test_set, original_test_set_label\n",
        "\n",
        "    #Returns train dataset to users. Default transformation is True as we want to train with augmented data\n",
        "    def get_train_dataset(self, transform = True):\n",
        "        # original_train_set = torch.empty((training_size, 3, 32, 32), dtype=float)\n",
        "        original_train_set = [] \n",
        "        original_train_set_label = []\n",
        "        \n",
        "        for i, data in enumerate(self.cifar_train_set.data):\n",
        "            data = Image.fromarray(data)\n",
        "\n",
        "            if transform:\n",
        "              data_transformed = self.transform(data)\n",
        "              original_train_set.append(data_transformed)\n",
        "              original_train_set_label.append(self.cifar_train_set.targets[i])\n",
        "            \n",
        "            data = self.no_transform(data)\n",
        "\n",
        "            original_train_set.append(data)\n",
        "            original_train_set_label.append(self.cifar_train_set.targets[i])\n",
        "\n",
        "        original_train_set = torch.stack(original_train_set)\n",
        "        original_train_set_label = F.one_hot(torch.tensor(original_train_set_label))\n",
        "\n",
        "        return original_train_set, original_train_set_label\n",
        "        \n",
        "\n",
        "    #Core logic for mixing image_dataset, input images and labels returned from get_train_dataset\n",
        "    #Default algo is set to bc mixing, input \"bc+\" for advanced mixing\n",
        "    def mix_image_dataset(self, images, labels, algo=\"bc\"):\n",
        "        mixed_images = []\n",
        "        mix_labels = []\n",
        "        mix_ratios = []\n",
        "        mixing_algo = self.mix_images_bc_plus if algo == \"bc+\" else self.mix_images_bc\n",
        "        total = 0\n",
        "\n",
        "        random.seed(10)\n",
        "        for offset in range(1, 100):\n",
        "            if total >= images.shape[0]: break\n",
        "            for i in range(images.shape[0] - 1):\n",
        "                if total >= images.shape[0]: break\n",
        "                if i + offset < images.shape[0] and not torch.all(torch.eq(labels[i], labels[i + offset])):\n",
        "                    m_i, ratio = mixing_algo(images[i], images[i + offset])\n",
        "                    mixed_images.append(m_i)\n",
        "                    mix_labels.append(labels[i])\n",
        "                    mix_ratios.append(ratio)\n",
        "                    total += 1\n",
        "\n",
        "        \n",
        "        return torch.stack(mixed_images), torch.stack(mix_labels), torch.tensor(mix_ratios)\n",
        "            \n",
        "                "
      ],
      "metadata": {
        "id": "3BrerS6fvbNf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Classes of CIFAR-10\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "uzpLn9SPvbQY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting up the datasets that will be used\n",
        "mixer = Mixer()\n",
        "\n",
        "original_test_set, original_test_set_label = mixer.get_test_dataset(transform=False)\n",
        "original_train_set, original_train_set_label = mixer.get_train_dataset(transform=False)\n",
        "\n",
        "mixing_train_set, mixing_train_set_label = mixer.get_train_dataset()\n",
        "\n",
        "mixed_train_images, mixed_train_labels, mix_train_ratios = mixer.mix_image_dataset(mixing_train_set, mixing_train_set_label, algo=\"bc\")\n",
        "plus_mixed_train_images, plus_mixed_train_labels, plus_mixed_train_ratios = mixer.mix_image_dataset(mixing_train_set, mixing_train_set_label, algo=\"bc+\") "
      ],
      "metadata": {
        "id": "LCBK8T2evlDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preview of the images from BC mixing, BC+ mixing and original images from CIFAR-10"
      ],
      "metadata": {
        "id": "d06X1tNO8QKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preview of the images within our mixed images\n",
        "\n",
        "#BC naiive mixing method plot\n",
        "fig, axs = plt.subplots(3, 6)\n",
        "fig.set_dpi(160)\n",
        "fig.suptitle(\"BC naive mixing method\")\n",
        "for i in range(3):\n",
        "    for j in range(6):\n",
        "        r_index = i * 8 + j\n",
        "        img = mixed_train_images[r_index] / 2 + 0.5\n",
        "        axs[i, j].imshow(np.transpose(img, (1, 2,0)))\n",
        "        axs[i, j].axis('off')\n",
        "        image_label = torch.nonzero(mixed_train_labels[r_index])\n",
        "        axs[i,j].set_title(\"{} \\n ratio: {:.4f}\".format(classes[image_label[0]], float(mix_train_ratios[r_index])),\n",
        "        fontdict={'fontsize':6})\n",
        "\n",
        "plt.show()\n",
        "\n",
        "#BC+ mixing method plot\n",
        "fig, axs = plt.subplots(3, 6)\n",
        "fig.set_dpi(160)\n",
        "fig.suptitle(\"BC+ mixing method\")\n",
        "for i in range(3):\n",
        "    for j in range(6):\n",
        "        r_index = i * 8 + j\n",
        "        img = plus_mixed_train_images[r_index] / 2 + 0.5\n",
        "        axs[i, j].imshow(np.transpose(img, (1, 2,0)))\n",
        "        axs[i, j].axis('off')\n",
        "        image_label = torch.nonzero(plus_mixed_train_labels[r_index])\n",
        "        axs[i,j].set_title(\"{} \\n ratio: {:.4f}\".format(classes[image_label[0]], float(plus_mixed_train_ratios[r_index])),\n",
        "        fontdict={'fontsize':6})\n",
        "\n",
        "plt.show()\n",
        "\n",
        "#Original CIFAR-10 images plot\n",
        "fig, axs = plt.subplots(3, 6)\n",
        "fig.set_dpi(160)\n",
        "fig.suptitle(\"Original training dataset\")\n",
        "for i in range(3):\n",
        "    for j in range(6):\n",
        "        r_index = i * 8 + j\n",
        "        img = original_train_set[r_index] / 2 + 0.5\n",
        "        axs[i, j].imshow(np.transpose(img, (1, 2,0)))\n",
        "        axs[i, j].axis('off')\n",
        "        image_label = torch.nonzero(original_train_set_label[r_index])\n",
        "        axs[i,j].set_title(\"{} \\n\".format(classes[image_label[0]]),\n",
        "        fontdict={'fontsize':6})\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0d5oXurDvlHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DatasetIterator class\n",
        "This is used for iterating through the datset, which would be used as an input to the pytorch DataLoader class."
      ],
      "metadata": {
        "id": "KuQy3pF-8fAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class DatasetIterator(Dataset):\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "  \n",
        "    def __len__(self):\n",
        "        return self.images.shape[0]\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        # return self.transform(self.images[index]), self.transform(self.labels[index])\n",
        "        return self.images[index].detach().cpu().numpy(), self.labels[index].detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "s5Z2_G59vlJz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ModelManager class\n",
        "This class is used for managing the models trained in this experiment.\n",
        "\n",
        "Inputs:\n",
        "* **Classifer**: The model that will be trained and tested\n",
        "* **Optimizer**: Optimizer that will be used during training\n",
        "* **l_function**: Loss function that will be used during training. By default it is kl_divergence.\n",
        "\n",
        "***Highly recommended to input a loss function as kl_divergence is very unstable and could result in the model returning NaN***\n",
        "\n"
      ],
      "metadata": {
        "id": "5OVdYqe58yPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelManager:\n",
        "    def __init__(self, classifier, optimizer, l_function = None):\n",
        "        self.classifier = classifier\n",
        "        self.optimizer = optimizer\n",
        "        self.l_function = l_function if l_function is not None else self.kl_divergence\n",
        "        self.train_losses = []\n",
        "        self.train_counter = []\n",
        "    \n",
        "    #KL-divergence that was implemented in the original paper\n",
        "    def kl_divergence(self, pred, true):\n",
        "        entropy = -1 * torch.sum(true[torch.nonzero(true, as_tuple=True)] * torch.log(true[torch.nonzero(true, as_tuple=True)]))\n",
        "        crossEntropy = -1 * torch.sum(true * torch.nn.functional.log_softmax(pred))\n",
        "        return (crossEntropy - entropy) / pred.shape[0]\n",
        "\n",
        "    \n",
        "    def train_model(self, train_loader, epoch):\n",
        "      epoch_loss = 0\n",
        "      self.classifier.train()\n",
        "      for batch_idx, (images, targets) in enumerate(train_loader):\n",
        "        images, targets = images.float(), targets.float()\n",
        "        images = images.to(device)\n",
        "        targets = targets.to(device)\n",
        "        self.optimizer.zero_grad()\n",
        "        output = self.classifier(images)\n",
        "        loss = self.l_function(output, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        if batch_idx % 100 == 0:\n",
        "          self.train_losses.append(loss.item()) # item() is to get the value of the tensor directly\n",
        "          self.train_counter.append((batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
        "          print(f'Epoch {epoch}: [{batch_idx*len(images)}/{len(train_loader.dataset)}] Loss: {loss.item()}')\n",
        "      \n",
        "      print(f\"Average loss for Epoch {epoch}: {epoch_loss / len(train_loader.dataset)}\")\n",
        "    \n",
        "    def test_model(self, test_loader):\n",
        "        correct, total = 0, 0\n",
        "        self.classifier.eval()\n",
        "        with torch.no_grad():\n",
        "            for data in test_loader:\n",
        "                images, labels = data\n",
        "                images, labels = images.float(), labels.float()\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = self.classifier(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                labels = [int(torch.nonzero(x)) for x in labels]\n",
        "                total += len(labels)\n",
        "                correct += sum([1 for x in range(len(labels)) if predicted[x] == labels[x]])\n",
        "        print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))"
      ],
      "metadata": {
        "id": "tQ0ZQGeNvlMZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pretrained Resnet-18 Model"
      ],
      "metadata": {
        "id": "1thyRTNpvyTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "KSq4R2EIvuCS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training a model now\n",
        "def get_resnet18_model(pretrained=True):\n",
        "  resnet18 = models.resnet18(pretrained = True)\n",
        "  resnet18.fc = nn.Linear(resnet18.fc.in_features, mixed_train_labels[0].shape[0])\n",
        "  resnet18.layer4.requires_grad = True\n",
        "  resnet18.layer3.requires_grad = True\n",
        "  resnet18.conv1.requires_grad = True\n",
        "  resnet18.layer1.requires_grad = True\n",
        "  resnet18.layer2.requires_grad = True\n",
        "  resnet18 = resnet18.float()\n",
        "  \n",
        "  return resnet18"
      ],
      "metadata": {
        "id": "wU8tbDJ7vzUx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convnet Model from Paper"
      ],
      "metadata": {
        "id": "q8WZrc0kdTXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBNReLU(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, ksize, stride = 1, pad = 0, bias=False):\n",
        "        super(ConvBNReLU, self).__init__()\n",
        "        self.conv = torch.nn.Conv2d(in_channels, out_channels, ksize, stride, pad, bias=bias)\n",
        "        self.bn = torch.nn.BatchNorm2d(out_channels, eps=1e-5)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        output = self.conv(x)\n",
        "        output = self.bn(output)\n",
        "\n",
        "        return torch.relu(output)\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv11 = ConvBNReLU(3, 64, 3, pad = 1)\n",
        "        self.conv12 = ConvBNReLU(64, 64, 3, pad = 1)\n",
        "        self.conv21 = ConvBNReLU(64, 128, 3, pad = 1)\n",
        "        self.conv22 = ConvBNReLU(128, 128, 3, pad = 1)\n",
        "        self.conv31 = ConvBNReLU(128, 256, 3, pad = 1)\n",
        "        self.conv32 = ConvBNReLU(256, 256, 3, pad = 1)\n",
        "        self.conv33 = ConvBNReLU(256, 256, 3, pad = 1)\n",
        "        self.conv34 = ConvBNReLU(256, 256, 3, pad = 1)\n",
        "        self.fc4 = torch.nn.Linear(256*4*4, 1024)\n",
        "        self.fc5 = torch.nn.Linear(1024, 1024)\n",
        "        self.fc6 = torch.nn.Linear(1024, n_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        output = self.conv11(x)\n",
        "        output = self.conv12(output)\n",
        "        output = nn.functional.max_pool2d(output, 2)\n",
        "\n",
        "\n",
        "        output = self.conv21(output)\n",
        "        output = self.conv22(output)\n",
        "        output = nn.functional.max_pool2d(output, 2)\n",
        "\n",
        "\n",
        "        output = self.conv31(output)\n",
        "        output = self.conv32(output)\n",
        "        output = self.conv33(output)\n",
        "        output = self.conv34(output)\n",
        "        output = nn.functional.max_pool2d(output, 2)\n",
        "        output = output.reshape(-1, 256*4*4)\n",
        "\n",
        "        output = nn.functional.dropout(nn.functional.relu(self.fc4(output)))\n",
        "        output = nn.functional.dropout(nn.functional.relu(self.fc5(output)))\n",
        "\n",
        "        return self.fc6(output)"
      ],
      "metadata": {
        "id": "2X00N9CZdTmj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shake Shake Regularization \n",
        "(https://notebook.community/t-vi/pytorch-tvmisc/misc/cifar10-shake-shake)"
      ],
      "metadata": {
        "id": "feT_mtdzu4D5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Variable\n",
        "# shakeshake net leaning heavily on the original torch implementation https://github.com/xgastaldi/shake-shake/\n",
        "class ShakeShakeBlock2d(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride, per_image=True, rand_forward=True, rand_backward=True):\n",
        "        super().__init__()\n",
        "        self.same_width = (in_channels==out_channels)\n",
        "        self.per_image = per_image\n",
        "        self.rand_forward = rand_forward\n",
        "        self.rand_backward = rand_backward\n",
        "        self.stride = stride\n",
        "        self.net1, self.net2 = [torch.nn.Sequential(\n",
        "                        torch.nn.ReLU(),\n",
        "                        torch.nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1),\n",
        "                        torch.nn.BatchNorm2d(out_channels),\n",
        "                        torch.nn.ReLU(),\n",
        "                        torch.nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "                        torch.nn.BatchNorm2d(out_channels)) for i in range(2)]\n",
        "        if not self.same_width:\n",
        "            self.skip_conv1 = torch.nn.Conv2d(in_channels, out_channels//2, 1)\n",
        "            self.skip_conv2 = torch.nn.Conv2d(in_channels, out_channels//2, 1)\n",
        "            self.skip_bn = torch.nn.BatchNorm2d(out_channels)\n",
        "    def forward(self, inp):\n",
        "        if self.same_width:\n",
        "            skip = inp\n",
        "        else:\n",
        "            # double check, this seems to be a fancy way to trow away the top-right and bottom-left of each 2x2 patch (with stride=2)\n",
        "            x1 = torch.nn.functional.avg_pool2d(inp, 1, stride=self.stride)\n",
        "            x1 = self.skip_conv1(x1)\n",
        "            x2 = torch.nn.functional.pad(inp, (1,-1,1,-1))            # this makes the top and leftmost row 0. one could use -1,1\n",
        "            x2 = torch.nn.functional.avg_pool2d(x2, 1, stride=self.stride)\n",
        "            x2 = self.skip_conv2(x2)\n",
        "            skip = torch.cat((x1,x2), dim=1)\n",
        "            skip = self.skip_bn(skip)\n",
        "        x1 = self.net1(inp)\n",
        "        x2 = self.net2(inp)\n",
        "\n",
        "        if self.training:\n",
        "            if self.rand_forward:\n",
        "                if self.per_image:\n",
        "                    alpha = Variable(inp.data.new(inp.size(0),1,1,1).uniform_())\n",
        "                else:\n",
        "                    alpha = Variable(inp.data.new(1,1,1,1).uniform_())\n",
        "            else:\n",
        "                alpha = 0.5\n",
        "            if self.rand_backward:\n",
        "                if self.per_image:\n",
        "                    beta = Variable(inp.data.new(inp.size(0),1,1,1).uniform_())\n",
        "                else:\n",
        "                    beta = Variable(inp.data.new(1,1,1,1).uniform_())\n",
        "            else:\n",
        "                beta = 0.5\n",
        "            # this is the trick to get beta in the backward (because it does not see the detatched)\n",
        "            # and alpha in the forward (when it sees the detached with the alpha and the beta cancel)\n",
        "            x = skip+beta*x1+(1-beta)*x2+((alpha-beta)*x1).detach()+((beta-alpha)*x2).detach()\n",
        "        else:\n",
        "            x = skip+0.5*(x1+x2)\n",
        "        return x\n",
        "\n",
        "            \n",
        "class ShakeShakeBlocks2d(torch.nn.Sequential):\n",
        "    def __init__(self, in_channels, out_channels, depth, stride, per_image=True, rand_forward=True, rand_backward=True):\n",
        "        super().__init__(*[\n",
        "            ShakeShakeBlock2d(in_channels if i==0 else out_channels, out_channels, stride if i==0 else 1,\n",
        "                              per_image, rand_forward, rand_backward) for i in range(depth)])\n",
        "\n",
        "class ShakeShakeNet(torch.nn.Module):\n",
        "    def __init__(self, depth=20, basewidth=32, per_image=True, rand_forward=True, rand_backward=True, num_classes=16):\n",
        "        super().__init__()\n",
        "        assert (depth - 2) % 6==0, \"depth should be n*6+2\"\n",
        "        n = (depth - 2) // 6\n",
        "        self.inconv = torch.nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(16)\n",
        "        self.s1 = ShakeShakeBlocks2d(16, basewidth, n, 1, per_image, rand_forward, rand_backward)\n",
        "        self.s2 = ShakeShakeBlocks2d(basewidth, 2*basewidth, n, 2, per_image, rand_forward, rand_backward)\n",
        "        self.s3 = ShakeShakeBlocks2d(2*basewidth, 4*basewidth, n, 2, per_image, rand_forward, rand_backward)\n",
        "        self.fc = torch.nn.Linear(4*basewidth, num_classes)\n",
        "    def forward(self, x):\n",
        "        x = self.inconv(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.s1(x)\n",
        "        x = self.s2(x)\n",
        "        x = self.s3(x)\n",
        "        x = torch.nn.functional.relu(x)\n",
        "        x = x.view(x.size(0), x.size(1), -1).mean(2)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "LaAWOQ65u4RI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BC Mixing algorithm training"
      ],
      "metadata": {
        "id": "u0_L3wpAdoR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specification of the # of epochs and the batch-size for training\n",
        "EPOCH = 20\n",
        "BATCH_SIZE = 128"
      ],
      "metadata": {
        "id": "JoOp23GsA-So"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bc_mixed_train_images, bc_mixed_train_labels = mixed_train_images, mixed_train_labels\n",
        "\n",
        "#Preparing train-loader of BC mixed dataset for pytorch DataLoader class\n",
        "bc_mixed_cifar10_dataset = DatasetIterator(bc_mixed_train_images, bc_mixed_train_labels)\n",
        "bc_mixed_train_loader = torch.utils.data.DataLoader(bc_mixed_cifar10_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "#Preparing test-loader for pytorch DataLoader class\n",
        "cifar10_test_dataset = DatasetIterator(original_test_set, original_test_set_label)\n",
        "cifar10_test_loader = torch.utils.data.DataLoader(cifar10_test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "ol9pVdR5dz7v"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training resnet-18 with BC mixed CIFAR-10 dataset"
      ],
      "metadata": {
        "id": "-AGN3W1p_36S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING RESNET18 WITH BC MIXING ALGORITHM\n",
        "epochs = EPOCH\n",
        "\n",
        "l_function = torch.nn.CrossEntropyLoss()\n",
        "# l_function = None #Uncomment to use KL Divergence Loss Function\n",
        "\n",
        "resnet18_bc = get_resnet18_model()\n",
        "optimizer = optim.SGD(resnet18_bc.parameters(), lr=0.0001, momentum=0.8)\n",
        "# optimizer = optim.Adam(resnet18_bc.parameters(), lr = 0.0001) #Uncomment for Adam optimizer\n",
        "\n",
        "resnet18_bc = resnet18_bc.to(device)\n",
        "\n",
        "resnet18_bc_model_manager = ModelManager(resnet18_bc, optimizer, l_function)\n",
        "\n",
        "for e in range(1, epochs + 1):\n",
        "  resnet18_bc_model_manager.train_model(bc_mixed_train_loader, e)\n",
        "\n",
        "# Uncomment if you want to save the model\n",
        "# resnet18_bc = resnet18_bc.to('cpu')\n",
        "# save_model('resnet18_bc', PATH, resnet18_bc)\n",
        "# resnet18_bc = resnet18_bc.to(device)"
      ],
      "metadata": {
        "id": "jDXlYDi9v2Tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training convnet with BC mixed CIFAR-10 dataset"
      ],
      "metadata": {
        "id": "mByc3o70AC0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING convnet WITH BC MIXING ALGORITHM\n",
        "epochs = EPOCH\n",
        "\n",
        "convnet_bc = ConvNet(10)\n",
        "optimizer = optim.SGD(convnet_bc.parameters(), lr=0.01, momentum=0.8)\n",
        "# optimizer = optim.Adam(convnet_bc.parameters(), lr = 0.01) #Uncomment for Adam optimizer\n",
        "\n",
        "l_function = torch.nn.CrossEntropyLoss()\n",
        "# l_function = None #Uncomment to use KL Divergence Loss Function\n",
        "\n",
        "convnet_bc = convnet_bc.to(device)\n",
        "\n",
        "convnet_bc_model_manager = ModelManager(convnet_bc, optimizer, l_function)\n",
        "\n",
        "for e in range(1, epochs + 1):\n",
        "  convnet_bc_model_manager.train_model(bc_mixed_train_loader, e)\n",
        "\n",
        "# Uncomment if you want to save the model\n",
        "# convnet_bc = convnet_bc.to('cpu')\n",
        "# save_model('convnet_bc', PATH, convnet_bc)\n",
        "# convnet_bc = convnet_bc.to(device)\n"
      ],
      "metadata": {
        "id": "GVYWdOLdhAHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Shake-Shake Regularization with BC mixed CIFAR-10 dataset"
      ],
      "metadata": {
        "id": "Fh4KDxYqAFsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING Shake-Shake Reglarization WITH BC MIXING ALGORITHM\n",
        "epochs = EPOCH\n",
        "\n",
        "l_function = torch.nn.CrossEntropyLoss()\n",
        "# l_function = None #Uncomment to use KL Divergence Loss Function\n",
        "\n",
        "shake_bc = ShakeShakeNet(num_classes=10, depth=8)\n",
        "optimizer = optim.SGD(shake_bc.parameters(), lr=0.01, momentum=0.8)\n",
        "# optimizer = optim.Adam(shake_bc.parameters(), lr = 0.01) #Uncomment for Adam optimizer\n",
        "\n",
        "shake_bc = shake_bc.to(device)\n",
        "\n",
        "shake_bc_model_manager = ModelManager(shake_bc, optimizer, l_function)\n",
        "\n",
        "for e in range(1, epochs + 1):\n",
        "  shake_bc_model_manager.train_model(bc_mixed_train_loader, e)\n",
        "\n",
        "# Uncomment if you want to save the model\n",
        "# shake_bc = shake_bc.to('cpu')\n",
        "# save_model('shake_bc', PATH, shake_bc)\n",
        "# shake_bc = shake_bc.to(device)"
      ],
      "metadata": {
        "id": "3tVygQftvSsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing accuracy of the models being trained on BC mixed CIFAR-10 model"
      ],
      "metadata": {
        "id": "xvy4ZgjS_qiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing of BC Pretrained Resnet18 with dataset without transformation:\")\n",
        "resnet18_bc_model_manager.test_model(cifar10_test_loader)\n",
        "\n",
        "print(\"\\nTesting of BC convnet with dataset without transformation:\")\n",
        "convnet_bc_model_manager.test_model(cifar10_test_loader)\n",
        "\n",
        "print(\"\\nTesting of BC shake-shake with dataset without transformation:\")\n",
        "shake_bc_model_manager.test_model(cifar10_test_loader)"
      ],
      "metadata": {
        "id": "3dh487AHjwXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization of Training Loss of BC algorithm between Resnet18, Convnet and Shake-Shake Regularization"
      ],
      "metadata": {
        "id": "gTqOiug2gnK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8,6))\n",
        "ax1 = fig.add_subplot(111)\n",
        "\n",
        "bc_train_counter = resnet18_bc_model_manager.train_counter\n",
        "resnet18_bc_train_loss, convnet_bc_train_loss = resnet18_bc_model_manager.train_losses, convnet_bc_model_manager.train_losses\n",
        "shake_bc_train_loss = shake_bc_model_manager.train_losses\n",
        "\n",
        "ax1.scatter(bc_train_counter, resnet18_bc_train_loss, c='b', marker=\"o\", label='resnet18')\n",
        "ax1.scatter(bc_train_counter, convnet_bc_train_loss, s=10, c='r', marker=\"x\", label='convnet')\n",
        "ax1.scatter(bc_train_counter, shake_bc_train_loss, s=10, c='g', marker=\"s\", label='shake-shake')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Loss of model trained with BC algorithm')\n",
        "plt.xlabel('Training Counter')\n",
        "plt.ylabel('Training Loss value')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L_NlxCl3Zned"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BC+ Mixing algorithm training"
      ],
      "metadata": {
        "id": "PPzYdwinmhOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specification of the # of epochs and the batch-size for training\n",
        "EPOCH = 20\n",
        "BATCH_SIZE = 128"
      ],
      "metadata": {
        "id": "2zz_HMr0l_IS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bc_plus_mixed_train_images, bc_plus_mixed_train_labels = plus_mixed_train_images, plus_mixed_train_labels\n",
        "\n",
        "#Preparing train-loader of BC+ mixed dataset for pytorch DataLoader class\n",
        "bc_plus_mixed_cifar10_dataset = DatasetIterator(bc_plus_mixed_train_images, bc_plus_mixed_train_labels)\n",
        "bc_plus_mixed_train_loader = torch.utils.data.DataLoader(bc_plus_mixed_cifar10_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "#Preparing train-loader of original test dataset for pytorch DataLoader class\n",
        "cifar10_test_dataset = DatasetIterator(original_test_set, original_test_set_label)\n",
        "cifar10_test_loader = torch.utils.data.DataLoader(cifar10_test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "qHT-05aWmhgL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training resnet-18 with BC+ mixed CIFAR-10 dataset"
      ],
      "metadata": {
        "id": "qe3vQ5ZKBPN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING RESNET18 WITH BC+ MIXING ALGORITHM\n",
        "epochs = EPOCH\n",
        "\n",
        "l_function = torch.nn.CrossEntropyLoss()\n",
        "# l_function = None #Uncomment to use KL Divergence Loss Function\n",
        "\n",
        "resnet18_bc_plus = get_resnet18_model()\n",
        "optimizer = optim.SGD(resnet18_bc_plus.parameters(), lr=0.0001, momentum=0.8)\n",
        "# optimizer = optim.Adam(resnet18_bc_plus.parameters(), lr = 0.0001) #Uncomment for Adam optimizer\n",
        "\n",
        "resnet18_bc_plus = resnet18_bc_plus.to(device)\n",
        "\n",
        "resnet18_bc_plus_model_manager = ModelManager(resnet18_bc_plus, optimizer, l_function)\n",
        "\n",
        "for e in range(1, epochs + 1):\n",
        "  resnet18_bc_plus_model_manager.train_model(bc_plus_mixed_train_loader, e)\n",
        "\n",
        "# Uncomment if you want to save the model\n",
        "# resnet18_bc_plus = resnet18_bc_plus.to('cpu')\n",
        "# save_model('resnet18_bc_plus', PATH, resnet18_bc_plus)\n",
        "# resnet18_bc_plus = resnet18_bc_plus.to(device)"
      ],
      "metadata": {
        "id": "0OadT6b_m3Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Convnet with BC+ mixed CIFAR-10 dataset"
      ],
      "metadata": {
        "id": "lRbkP81sBQsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING convnet WITH BC+ MIXING ALGORITHM\n",
        "epochs = EPOCH\n",
        "\n",
        "convnet_bc_plus = ConvNet(10)\n",
        "optimizer = optim.SGD(convnet_bc_plus.parameters(), lr=0.01, momentum=0.8)\n",
        "# optimizer = optim.Adam(convnet_bc_plus.parameters(), lr = 0.01) #Uncomment for Adam optimizer\n",
        "\n",
        "l_function = torch.nn.CrossEntropyLoss()\n",
        "# l_function = None #Uncomment to use KL Divergence Loss Function\n",
        "\n",
        "convnet_bc_plus = convnet_bc_plus.to(device)\n",
        "\n",
        "convnet_bc_plus_model_manager = ModelManager(convnet_bc_plus, optimizer, l_function)\n",
        "\n",
        "for e in range(1, epochs + 1):\n",
        "  convnet_bc_plus_model_manager.train_model(bc_plus_mixed_train_loader, e)\n",
        "\n",
        "# Uncomment if you want to save the model\n",
        "# convnet_bc_plus = convnet_bc_plus.to('cpu')\n",
        "# save_model('convnet_bc_plus', PATH, convnet_bc_plus)\n",
        "# convnet_bc_plus = convnet_bc_plus.to(device)"
      ],
      "metadata": {
        "id": "kOIl7sPRm3UR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Shake-Shake Regularization with BC mixed CIFAR-10 dataset"
      ],
      "metadata": {
        "id": "WtvmHaJ4BkyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING shake-shake WITH BC+ MIXING ALGORITHM\n",
        "epochs = EPOCH\n",
        "\n",
        "l_function = torch.nn.CrossEntropyLoss()\n",
        "# l_function = None #Uncomment to use KL Divergence Loss Function\n",
        "\n",
        "shake_bc_plus = ShakeShakeNet(num_classes=10, depth=8)\n",
        "optimizer = optim.SGD(shake_bc_plus.parameters(), lr=0.01, momentum=0.8)\n",
        "# optimizer = optim.Adam(shake_bc_plus.parameters(), lr = 0.01) #Uncomment for Adam optimizer\n",
        "\n",
        "shake_bc_plus = shake_bc_plus.to(device)\n",
        "\n",
        "shake_bc_plus_model_manager = ModelManager(shake_bc_plus, optimizer, l_function)\n",
        "\n",
        "for e in range(1, epochs + 1):\n",
        "  shake_bc_plus_model_manager.train_model(bc_plus_mixed_train_loader, e)\n",
        "\n",
        "# Uncomment if you want to save the model\n",
        "# shake_bc_plus = shake_bc_plus.to('cpu')\n",
        "# save_model('shake_bc_plus', PATH, shake_bc_plus)\n",
        "# shake_bc_plus = shake_bc_plus.to(device)"
      ],
      "metadata": {
        "id": "a1nxr3vqy5Nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing accuracy of the models being trained on BC+ mixed CIFAR-10 model"
      ],
      "metadata": {
        "id": "mBLDZ7mu_yKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing of BC+ Pretrained Resnet18 with original dataset:\")\n",
        "resnet18_bc_plus_model_manager.test_model(cifar10_test_loader)\n",
        "\n",
        "print(\"\\nTesting of BC+ convnet with original dataset:\")\n",
        "convnet_bc_plus_model_manager.test_model(cifar10_test_loader)\n",
        "\n",
        "print(\"\\nTesting of BC+ shake-shake with original dataset:\")\n",
        "shake_bc_plus_model_manager.test_model(cifar10_test_loader)"
      ],
      "metadata": {
        "id": "VglrPexe-crf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization of Training Loss of BC+ algorithm between Resnet18, Convnet and Shake-Shake Regularization"
      ],
      "metadata": {
        "id": "9sNv1rvNnB2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8,6))\n",
        "ax1 = fig.add_subplot(111)\n",
        "\n",
        "bc_plus_train_counter = resnet18_bc_plus_model_manager.train_counter\n",
        "resnet18_bc_plus_train_loss, convnet_bc_plus_train_loss = resnet18_bc_plus_model_manager.train_losses, convnet_bc_plus_model_manager.train_losses\n",
        "shake_bc_plus_train_loss = shake_bc_plus_model_manager.train_losses\n",
        "\n",
        "ax1.scatter(bc_plus_train_counter, resnet18_bc_plus_train_loss, c='b', marker=\"o\", label='resnet18')\n",
        "ax1.scatter(bc_plus_train_counter, convnet_bc_plus_train_loss, s=10, c='r', marker=\"x\", label='convnet')\n",
        "ax1.scatter(bc_plus_train_counter, shake_bc_plus_train_loss, s=10, c='g', marker=\"s\", label='shake-shake')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Loss of model trained with BC+ algorithm')\n",
        "plt.xlabel('Training Counter')\n",
        "plt.ylabel('Training Loss value')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qL-JZ3Pym9fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Models on non-augmented CIFAR-10 Dataset"
      ],
      "metadata": {
        "id": "rLce9UPBB3ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Specification of the # of epochs and the batch-size for training\n",
        "EPOCH = 20\n",
        "BATCH_SIZE = 128"
      ],
      "metadata": {
        "id": "geLoSDwFClRN"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparing train-loader of non-augmented dataset for pytorch DataLoader class\n",
        "original_cifar10_dataset = DatasetIterator(original_train_set, original_train_set_label)\n",
        "original_train_loader = torch.utils.data.DataLoader(original_cifar10_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "cifar10_test_dataset = DatasetIterator(original_test_set, original_test_set_label)\n",
        "# Test loader with original CIFAR-10 test dataset without augmentation\n",
        "cifar10_test_loader = torch.utils.data.DataLoader(cifar10_test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "VYCOGgBGDRek"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training of all 3 models"
      ],
      "metadata": {
        "id": "U1RxHUAGEFmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING convnet, shake-shake, resnet18 WITH original dataset\n",
        "epochs = EPOCH\n",
        "l_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "convnet_original = ConvNet(10)\n",
        "shake_original = ShakeShakeNet(num_classes=10)\n",
        "resnet18_original = get_resnet18_model()\n",
        "\n",
        "optimizer_convnet = optim.SGD(convnet_original.parameters(), lr=0.01, momentum=0.8)\n",
        "optimizer_shake = optim.SGD(shake_original.parameters(), lr=0.01, momentum=0.8)\n",
        "optimizer_resnet18 = optim.SGD(resnet18_original.parameters(), lr=0.001, momentum=0.8)\n",
        "\n",
        "\n",
        "convnet_original = convnet_original.to(device)\n",
        "shake_original = shake_original.to(device)\n",
        "resnet18_original = resnet18_original.to(device)\n",
        "\n",
        "convnet_original_model_manager = ModelManager(convnet_original, optimizer_convnet, l_function)\n",
        "shake_original_model_manager = ModelManager(shake_original, optimizer_shake, l_function)\n",
        "resnet18_original_model_manager = ModelManager(resnet18_original, optimizer_resnet18, l_function)\n",
        "\n",
        "for e in range(1, epochs + 1):\n",
        "  convnet_original_model_manager.train_model(original_train_loader, e)\n",
        "  shake_original_model_manager.train_model(original_train_loader, e)\n",
        "  resnet18_original_model_manager.train_model(original_train_loader, e)"
      ],
      "metadata": {
        "id": "527dLn4oCevv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing accuracy of the models being trained on non-augmented CIFAR-10 model"
      ],
      "metadata": {
        "id": "184DF88fD2QQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing of Pretrained Resnet18 with original dataset:\")\n",
        "resnet18_original_model_manager.test_model(cifar10_test_loader)\n",
        "\n",
        "print(\"\\nTesting of convnet with original dataset:\")\n",
        "convnet_original_model_manager.test_model(cifar10_test_loader)\n",
        "\n",
        "print(\"\\nTesting of shake-shake with original dataset:\")\n",
        "shake_original_model_manager.test_model(cifar10_test_loader)"
      ],
      "metadata": {
        "id": "JpbnAdKRDAaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization of Training Loss without mixing between Resnet18, Convnet and Shake-Shake Regularization"
      ],
      "metadata": {
        "id": "Fp8XtjJMD7nY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8,6))\n",
        "ax1 = fig.add_subplot(111)\n",
        "\n",
        "original_train_counter = resnet18_original_model_manager.train_counter\n",
        "resnet18_original_train_loss, convnet_original_train_loss = resnet18_original_model_manager.train_losses, convnet_original_model_manager.train_losses\n",
        "shake_original_train_loss = shake_original_model_manager.train_losses\n",
        "\n",
        "ax1.scatter(original_train_counter, resnet18_original_train_loss, c='b', marker=\"o\", label='resnet18')\n",
        "ax1.scatter(original_train_counter, convnet_original_train_loss, s=10, c='r', marker=\"x\", label='convnet')\n",
        "ax1.scatter(original_train_counter, shake_original_train_loss, s=10, c='g', marker=\"s\", label='shake-shake')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Loss of model trained with original dataset')\n",
        "plt.xlabel('Training Counter')\n",
        "plt.ylabel('Training Loss value')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mXc0OjunDA8T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}